// Copyright 2025 Google LLC
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//     https://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

// Code generated by protoc-gen-go_gapic. DO NOT EDIT.

package gkerecommender

import (
	"bytes"
	"context"
	"fmt"
	"log/slog"
	"math"
	"net/http"
	"net/url"
	"time"

	gkerecommenderpb "cloud.google.com/go/gkerecommender/apiv1/gkerecommenderpb"
	gax "github.com/googleapis/gax-go/v2"
	"google.golang.org/api/iterator"
	"google.golang.org/api/option"
	"google.golang.org/api/option/internaloption"
	gtransport "google.golang.org/api/transport/grpc"
	httptransport "google.golang.org/api/transport/http"
	"google.golang.org/grpc"
	"google.golang.org/protobuf/encoding/protojson"
	"google.golang.org/protobuf/proto"
)

var newGkeInferenceQuickstartClientHook clientHook

// GkeInferenceQuickstartCallOptions contains the retry settings for each method of GkeInferenceQuickstartClient.
type GkeInferenceQuickstartCallOptions struct {
	FetchModels               []gax.CallOption
	FetchModelServers         []gax.CallOption
	FetchModelServerVersions  []gax.CallOption
	FetchProfiles             []gax.CallOption
	GenerateOptimizedManifest []gax.CallOption
	FetchBenchmarkingData     []gax.CallOption
}

func defaultGkeInferenceQuickstartGRPCClientOptions() []option.ClientOption {
	return []option.ClientOption{
		internaloption.WithDefaultEndpoint("gkerecommender.googleapis.com:443"),
		internaloption.WithDefaultEndpointTemplate("gkerecommender.UNIVERSE_DOMAIN:443"),
		internaloption.WithDefaultMTLSEndpoint("gkerecommender.mtls.googleapis.com:443"),
		internaloption.WithDefaultUniverseDomain("googleapis.com"),
		internaloption.WithDefaultAudience("https://gkerecommender.googleapis.com/"),
		internaloption.WithDefaultScopes(DefaultAuthScopes()...),
		internaloption.EnableJwtWithScope(),
		internaloption.EnableNewAuthLibrary(),
		option.WithGRPCDialOption(grpc.WithDefaultCallOptions(
			grpc.MaxCallRecvMsgSize(math.MaxInt32))),
	}
}

func defaultGkeInferenceQuickstartCallOptions() *GkeInferenceQuickstartCallOptions {
	return &GkeInferenceQuickstartCallOptions{
		FetchModels: []gax.CallOption{
			gax.WithTimeout(60000 * time.Millisecond),
		},
		FetchModelServers: []gax.CallOption{
			gax.WithTimeout(60000 * time.Millisecond),
		},
		FetchModelServerVersions: []gax.CallOption{
			gax.WithTimeout(60000 * time.Millisecond),
		},
		FetchProfiles: []gax.CallOption{
			gax.WithTimeout(60000 * time.Millisecond),
		},
		GenerateOptimizedManifest: []gax.CallOption{
			gax.WithTimeout(60000 * time.Millisecond),
		},
		FetchBenchmarkingData: []gax.CallOption{
			gax.WithTimeout(60000 * time.Millisecond),
		},
	}
}

func defaultGkeInferenceQuickstartRESTCallOptions() *GkeInferenceQuickstartCallOptions {
	return &GkeInferenceQuickstartCallOptions{
		FetchModels: []gax.CallOption{
			gax.WithTimeout(60000 * time.Millisecond),
		},
		FetchModelServers: []gax.CallOption{
			gax.WithTimeout(60000 * time.Millisecond),
		},
		FetchModelServerVersions: []gax.CallOption{
			gax.WithTimeout(60000 * time.Millisecond),
		},
		FetchProfiles: []gax.CallOption{
			gax.WithTimeout(60000 * time.Millisecond),
		},
		GenerateOptimizedManifest: []gax.CallOption{
			gax.WithTimeout(60000 * time.Millisecond),
		},
		FetchBenchmarkingData: []gax.CallOption{
			gax.WithTimeout(60000 * time.Millisecond),
		},
	}
}

// internalGkeInferenceQuickstartClient is an interface that defines the methods available from GKE Recommender API.
type internalGkeInferenceQuickstartClient interface {
	Close() error
	setGoogleClientInfo(...string)
	Connection() *grpc.ClientConn
	FetchModels(context.Context, *gkerecommenderpb.FetchModelsRequest, ...gax.CallOption) *StringIterator
	FetchModelServers(context.Context, *gkerecommenderpb.FetchModelServersRequest, ...gax.CallOption) *StringIterator
	FetchModelServerVersions(context.Context, *gkerecommenderpb.FetchModelServerVersionsRequest, ...gax.CallOption) *StringIterator
	FetchProfiles(context.Context, *gkerecommenderpb.FetchProfilesRequest, ...gax.CallOption) *ProfileIterator
	GenerateOptimizedManifest(context.Context, *gkerecommenderpb.GenerateOptimizedManifestRequest, ...gax.CallOption) (*gkerecommenderpb.GenerateOptimizedManifestResponse, error)
	FetchBenchmarkingData(context.Context, *gkerecommenderpb.FetchBenchmarkingDataRequest, ...gax.CallOption) (*gkerecommenderpb.FetchBenchmarkingDataResponse, error)
}

// GkeInferenceQuickstartClient is a client for interacting with GKE Recommender API.
// Methods, except Close, may be called concurrently. However, fields must not be modified concurrently with method calls.
//
// GKE Inference Quickstart (GIQ) service provides profiles with performance
// metrics for popular models and model servers across multiple accelerators.
// These profiles help generate optimized best practices for running inference
// on GKE.
type GkeInferenceQuickstartClient struct {
	// The internal transport-dependent client.
	internalClient internalGkeInferenceQuickstartClient

	// The call options for this service.
	CallOptions *GkeInferenceQuickstartCallOptions
}

// Wrapper methods routed to the internal client.

// Close closes the connection to the API service. The user should invoke this when
// the client is no longer required.
func (c *GkeInferenceQuickstartClient) Close() error {
	return c.internalClient.Close()
}

// setGoogleClientInfo sets the name and version of the application in
// the `x-goog-api-client` header passed on each request. Intended for
// use by Google-written clients.
func (c *GkeInferenceQuickstartClient) setGoogleClientInfo(keyval ...string) {
	c.internalClient.setGoogleClientInfo(keyval...)
}

// Connection returns a connection to the API service.
//
// Deprecated: Connections are now pooled so this method does not always
// return the same resource.
func (c *GkeInferenceQuickstartClient) Connection() *grpc.ClientConn {
	return c.internalClient.Connection()
}

// FetchModels fetches available models. Open-source models follow the Huggingface Hub
// owner/model_name format.
func (c *GkeInferenceQuickstartClient) FetchModels(ctx context.Context, req *gkerecommenderpb.FetchModelsRequest, opts ...gax.CallOption) *StringIterator {
	return c.internalClient.FetchModels(ctx, req, opts...)
}

// FetchModelServers fetches available model servers. Open-source model servers use simplified,
// lowercase names (e.g., vllm).
func (c *GkeInferenceQuickstartClient) FetchModelServers(ctx context.Context, req *gkerecommenderpb.FetchModelServersRequest, opts ...gax.CallOption) *StringIterator {
	return c.internalClient.FetchModelServers(ctx, req, opts...)
}

// FetchModelServerVersions fetches available model server versions. Open-source servers use their own
// versioning schemas (e.g., vllm uses semver like v1.0.0).
//
// Some model servers have different versioning schemas depending on the
// accelerator. For example, vllm uses semver on GPUs, but returns nightly
// build tags on TPUs. All available versions will be returned when different
// schemas are present.
func (c *GkeInferenceQuickstartClient) FetchModelServerVersions(ctx context.Context, req *gkerecommenderpb.FetchModelServerVersionsRequest, opts ...gax.CallOption) *StringIterator {
	return c.internalClient.FetchModelServerVersions(ctx, req, opts...)
}

// FetchProfiles fetches available profiles. A profile contains performance metrics and
// cost information for a specific model server setup. Profiles can be
// filtered by parameters. If no filters are provided, all profiles are
// returned.
//
// Profiles display a single value per performance metric based on the
// provided performance requirements. If no requirements are given, the
// metrics represent the inflection point. See Run best practice inference
// with GKE Inference Quickstart
// recipes (at https://cloud.google.com/kubernetes-engine/docs/how-to/machine-learning/inference/inference-quickstart#how)
// for details.
func (c *GkeInferenceQuickstartClient) FetchProfiles(ctx context.Context, req *gkerecommenderpb.FetchProfilesRequest, opts ...gax.CallOption) *ProfileIterator {
	return c.internalClient.FetchProfiles(ctx, req, opts...)
}

// GenerateOptimizedManifest generates an optimized deployment manifest for a given model and model
// server, based on the specified accelerator, performance targets, and
// configurations. See Run best practice inference with GKE Inference
// Quickstart
// recipes (at https://cloud.google.com/kubernetes-engine/docs/how-to/machine-learning/inference/inference-quickstart)
// for deployment details.
func (c *GkeInferenceQuickstartClient) GenerateOptimizedManifest(ctx context.Context, req *gkerecommenderpb.GenerateOptimizedManifestRequest, opts ...gax.CallOption) (*gkerecommenderpb.GenerateOptimizedManifestResponse, error) {
	return c.internalClient.GenerateOptimizedManifest(ctx, req, opts...)
}

// FetchBenchmarkingData fetches all of the benchmarking data available for a profile. Benchmarking
// data returns all of the performance metrics available for a given model
// server setup on a given instance type.
func (c *GkeInferenceQuickstartClient) FetchBenchmarkingData(ctx context.Context, req *gkerecommenderpb.FetchBenchmarkingDataRequest, opts ...gax.CallOption) (*gkerecommenderpb.FetchBenchmarkingDataResponse, error) {
	return c.internalClient.FetchBenchmarkingData(ctx, req, opts...)
}

// gkeInferenceQuickstartGRPCClient is a client for interacting with GKE Recommender API over gRPC transport.
//
// Methods, except Close, may be called concurrently. However, fields must not be modified concurrently with method calls.
type gkeInferenceQuickstartGRPCClient struct {
	// Connection pool of gRPC connections to the service.
	connPool gtransport.ConnPool

	// Points back to the CallOptions field of the containing GkeInferenceQuickstartClient
	CallOptions **GkeInferenceQuickstartCallOptions

	// The gRPC API client.
	gkeInferenceQuickstartClient gkerecommenderpb.GkeInferenceQuickstartClient

	// The x-goog-* metadata to be sent with each request.
	xGoogHeaders []string

	logger *slog.Logger
}

// NewGkeInferenceQuickstartClient creates a new gke inference quickstart client based on gRPC.
// The returned client must be Closed when it is done being used to clean up its underlying connections.
//
// GKE Inference Quickstart (GIQ) service provides profiles with performance
// metrics for popular models and model servers across multiple accelerators.
// These profiles help generate optimized best practices for running inference
// on GKE.
func NewGkeInferenceQuickstartClient(ctx context.Context, opts ...option.ClientOption) (*GkeInferenceQuickstartClient, error) {
	clientOpts := defaultGkeInferenceQuickstartGRPCClientOptions()
	if newGkeInferenceQuickstartClientHook != nil {
		hookOpts, err := newGkeInferenceQuickstartClientHook(ctx, clientHookParams{})
		if err != nil {
			return nil, err
		}
		clientOpts = append(clientOpts, hookOpts...)
	}

	connPool, err := gtransport.DialPool(ctx, append(clientOpts, opts...)...)
	if err != nil {
		return nil, err
	}
	client := GkeInferenceQuickstartClient{CallOptions: defaultGkeInferenceQuickstartCallOptions()}

	c := &gkeInferenceQuickstartGRPCClient{
		connPool:                     connPool,
		gkeInferenceQuickstartClient: gkerecommenderpb.NewGkeInferenceQuickstartClient(connPool),
		CallOptions:                  &client.CallOptions,
		logger:                       internaloption.GetLogger(opts),
	}
	c.setGoogleClientInfo()

	client.internalClient = c

	return &client, nil
}

// Connection returns a connection to the API service.
//
// Deprecated: Connections are now pooled so this method does not always
// return the same resource.
func (c *gkeInferenceQuickstartGRPCClient) Connection() *grpc.ClientConn {
	return c.connPool.Conn()
}

// setGoogleClientInfo sets the name and version of the application in
// the `x-goog-api-client` header passed on each request. Intended for
// use by Google-written clients.
func (c *gkeInferenceQuickstartGRPCClient) setGoogleClientInfo(keyval ...string) {
	kv := append([]string{"gl-go", gax.GoVersion}, keyval...)
	kv = append(kv, "gapic", getVersionClient(), "gax", gax.Version, "grpc", grpc.Version, "pb", protoVersion)
	c.xGoogHeaders = []string{
		"x-goog-api-client", gax.XGoogHeader(kv...),
	}
}

// Close closes the connection to the API service. The user should invoke this when
// the client is no longer required.
func (c *gkeInferenceQuickstartGRPCClient) Close() error {
	return c.connPool.Close()
}

// Methods, except Close, may be called concurrently. However, fields must not be modified concurrently with method calls.
type gkeInferenceQuickstartRESTClient struct {
	// The http endpoint to connect to.
	endpoint string

	// The http client.
	httpClient *http.Client

	// The x-goog-* headers to be sent with each request.
	xGoogHeaders []string

	// Points back to the CallOptions field of the containing GkeInferenceQuickstartClient
	CallOptions **GkeInferenceQuickstartCallOptions

	logger *slog.Logger
}

// NewGkeInferenceQuickstartRESTClient creates a new gke inference quickstart rest client.
//
// GKE Inference Quickstart (GIQ) service provides profiles with performance
// metrics for popular models and model servers across multiple accelerators.
// These profiles help generate optimized best practices for running inference
// on GKE.
func NewGkeInferenceQuickstartRESTClient(ctx context.Context, opts ...option.ClientOption) (*GkeInferenceQuickstartClient, error) {
	clientOpts := append(defaultGkeInferenceQuickstartRESTClientOptions(), opts...)
	httpClient, endpoint, err := httptransport.NewClient(ctx, clientOpts...)
	if err != nil {
		return nil, err
	}

	callOpts := defaultGkeInferenceQuickstartRESTCallOptions()
	c := &gkeInferenceQuickstartRESTClient{
		endpoint:    endpoint,
		httpClient:  httpClient,
		CallOptions: &callOpts,
		logger:      internaloption.GetLogger(opts),
	}
	c.setGoogleClientInfo()

	return &GkeInferenceQuickstartClient{internalClient: c, CallOptions: callOpts}, nil
}

func defaultGkeInferenceQuickstartRESTClientOptions() []option.ClientOption {
	return []option.ClientOption{
		internaloption.WithDefaultEndpoint("https://gkerecommender.googleapis.com"),
		internaloption.WithDefaultEndpointTemplate("https://gkerecommender.UNIVERSE_DOMAIN"),
		internaloption.WithDefaultMTLSEndpoint("https://gkerecommender.mtls.googleapis.com"),
		internaloption.WithDefaultUniverseDomain("googleapis.com"),
		internaloption.WithDefaultAudience("https://gkerecommender.googleapis.com/"),
		internaloption.WithDefaultScopes(DefaultAuthScopes()...),
		internaloption.EnableNewAuthLibrary(),
	}
}

// setGoogleClientInfo sets the name and version of the application in
// the `x-goog-api-client` header passed on each request. Intended for
// use by Google-written clients.
func (c *gkeInferenceQuickstartRESTClient) setGoogleClientInfo(keyval ...string) {
	kv := append([]string{"gl-go", gax.GoVersion}, keyval...)
	kv = append(kv, "gapic", getVersionClient(), "gax", gax.Version, "rest", "UNKNOWN", "pb", protoVersion)
	c.xGoogHeaders = []string{
		"x-goog-api-client", gax.XGoogHeader(kv...),
	}
}

// Close closes the connection to the API service. The user should invoke this when
// the client is no longer required.
func (c *gkeInferenceQuickstartRESTClient) Close() error {
	// Replace httpClient with nil to force cleanup.
	c.httpClient = nil
	return nil
}

// Connection returns a connection to the API service.
//
// Deprecated: This method always returns nil.
func (c *gkeInferenceQuickstartRESTClient) Connection() *grpc.ClientConn {
	return nil
}
func (c *gkeInferenceQuickstartGRPCClient) FetchModels(ctx context.Context, req *gkerecommenderpb.FetchModelsRequest, opts ...gax.CallOption) *StringIterator {
	ctx = gax.InsertMetadataIntoOutgoingContext(ctx, c.xGoogHeaders...)
	opts = append((*c.CallOptions).FetchModels[0:len((*c.CallOptions).FetchModels):len((*c.CallOptions).FetchModels)], opts...)
	it := &StringIterator{}
	req = proto.Clone(req).(*gkerecommenderpb.FetchModelsRequest)
	it.InternalFetch = func(pageSize int, pageToken string) ([]string, string, error) {
		resp := &gkerecommenderpb.FetchModelsResponse{}
		if pageToken != "" {
			req.PageToken = proto.String(pageToken)
		}
		if pageSize > math.MaxInt32 {
			req.PageSize = proto.Int32(int32(math.MaxInt32))
		} else if pageSize != 0 {
			req.PageSize = proto.Int32(int32(pageSize))
		}
		err := gax.Invoke(ctx, func(ctx context.Context, settings gax.CallSettings) error {
			var err error
			resp, err = executeRPC(ctx, c.gkeInferenceQuickstartClient.FetchModels, req, settings.GRPC, c.logger, "FetchModels")
			return err
		}, opts...)
		if err != nil {
			return nil, "", err
		}

		it.Response = resp
		return resp.GetModels(), resp.GetNextPageToken(), nil
	}
	fetch := func(pageSize int, pageToken string) (string, error) {
		items, nextPageToken, err := it.InternalFetch(pageSize, pageToken)
		if err != nil {
			return "", err
		}
		it.items = append(it.items, items...)
		return nextPageToken, nil
	}

	it.pageInfo, it.nextFunc = iterator.NewPageInfo(fetch, it.bufLen, it.takeBuf)
	it.pageInfo.MaxSize = int(req.GetPageSize())
	it.pageInfo.Token = req.GetPageToken()

	return it
}

func (c *gkeInferenceQuickstartGRPCClient) FetchModelServers(ctx context.Context, req *gkerecommenderpb.FetchModelServersRequest, opts ...gax.CallOption) *StringIterator {
	ctx = gax.InsertMetadataIntoOutgoingContext(ctx, c.xGoogHeaders...)
	opts = append((*c.CallOptions).FetchModelServers[0:len((*c.CallOptions).FetchModelServers):len((*c.CallOptions).FetchModelServers)], opts...)
	it := &StringIterator{}
	req = proto.Clone(req).(*gkerecommenderpb.FetchModelServersRequest)
	it.InternalFetch = func(pageSize int, pageToken string) ([]string, string, error) {
		resp := &gkerecommenderpb.FetchModelServersResponse{}
		if pageToken != "" {
			req.PageToken = proto.String(pageToken)
		}
		if pageSize > math.MaxInt32 {
			req.PageSize = proto.Int32(int32(math.MaxInt32))
		} else if pageSize != 0 {
			req.PageSize = proto.Int32(int32(pageSize))
		}
		err := gax.Invoke(ctx, func(ctx context.Context, settings gax.CallSettings) error {
			var err error
			resp, err = executeRPC(ctx, c.gkeInferenceQuickstartClient.FetchModelServers, req, settings.GRPC, c.logger, "FetchModelServers")
			return err
		}, opts...)
		if err != nil {
			return nil, "", err
		}

		it.Response = resp
		return resp.GetModelServers(), resp.GetNextPageToken(), nil
	}
	fetch := func(pageSize int, pageToken string) (string, error) {
		items, nextPageToken, err := it.InternalFetch(pageSize, pageToken)
		if err != nil {
			return "", err
		}
		it.items = append(it.items, items...)
		return nextPageToken, nil
	}

	it.pageInfo, it.nextFunc = iterator.NewPageInfo(fetch, it.bufLen, it.takeBuf)
	it.pageInfo.MaxSize = int(req.GetPageSize())
	it.pageInfo.Token = req.GetPageToken()

	return it
}

func (c *gkeInferenceQuickstartGRPCClient) FetchModelServerVersions(ctx context.Context, req *gkerecommenderpb.FetchModelServerVersionsRequest, opts ...gax.CallOption) *StringIterator {
	ctx = gax.InsertMetadataIntoOutgoingContext(ctx, c.xGoogHeaders...)
	opts = append((*c.CallOptions).FetchModelServerVersions[0:len((*c.CallOptions).FetchModelServerVersions):len((*c.CallOptions).FetchModelServerVersions)], opts...)
	it := &StringIterator{}
	req = proto.Clone(req).(*gkerecommenderpb.FetchModelServerVersionsRequest)
	it.InternalFetch = func(pageSize int, pageToken string) ([]string, string, error) {
		resp := &gkerecommenderpb.FetchModelServerVersionsResponse{}
		if pageToken != "" {
			req.PageToken = proto.String(pageToken)
		}
		if pageSize > math.MaxInt32 {
			req.PageSize = proto.Int32(int32(math.MaxInt32))
		} else if pageSize != 0 {
			req.PageSize = proto.Int32(int32(pageSize))
		}
		err := gax.Invoke(ctx, func(ctx context.Context, settings gax.CallSettings) error {
			var err error
			resp, err = executeRPC(ctx, c.gkeInferenceQuickstartClient.FetchModelServerVersions, req, settings.GRPC, c.logger, "FetchModelServerVersions")
			return err
		}, opts...)
		if err != nil {
			return nil, "", err
		}

		it.Response = resp
		return resp.GetModelServerVersions(), resp.GetNextPageToken(), nil
	}
	fetch := func(pageSize int, pageToken string) (string, error) {
		items, nextPageToken, err := it.InternalFetch(pageSize, pageToken)
		if err != nil {
			return "", err
		}
		it.items = append(it.items, items...)
		return nextPageToken, nil
	}

	it.pageInfo, it.nextFunc = iterator.NewPageInfo(fetch, it.bufLen, it.takeBuf)
	it.pageInfo.MaxSize = int(req.GetPageSize())
	it.pageInfo.Token = req.GetPageToken()

	return it
}

func (c *gkeInferenceQuickstartGRPCClient) FetchProfiles(ctx context.Context, req *gkerecommenderpb.FetchProfilesRequest, opts ...gax.CallOption) *ProfileIterator {
	ctx = gax.InsertMetadataIntoOutgoingContext(ctx, c.xGoogHeaders...)
	opts = append((*c.CallOptions).FetchProfiles[0:len((*c.CallOptions).FetchProfiles):len((*c.CallOptions).FetchProfiles)], opts...)
	it := &ProfileIterator{}
	req = proto.Clone(req).(*gkerecommenderpb.FetchProfilesRequest)
	it.InternalFetch = func(pageSize int, pageToken string) ([]*gkerecommenderpb.Profile, string, error) {
		resp := &gkerecommenderpb.FetchProfilesResponse{}
		if pageToken != "" {
			req.PageToken = proto.String(pageToken)
		}
		if pageSize > math.MaxInt32 {
			req.PageSize = proto.Int32(int32(math.MaxInt32))
		} else if pageSize != 0 {
			req.PageSize = proto.Int32(int32(pageSize))
		}
		err := gax.Invoke(ctx, func(ctx context.Context, settings gax.CallSettings) error {
			var err error
			resp, err = executeRPC(ctx, c.gkeInferenceQuickstartClient.FetchProfiles, req, settings.GRPC, c.logger, "FetchProfiles")
			return err
		}, opts...)
		if err != nil {
			return nil, "", err
		}

		it.Response = resp
		return resp.GetProfile(), resp.GetNextPageToken(), nil
	}
	fetch := func(pageSize int, pageToken string) (string, error) {
		items, nextPageToken, err := it.InternalFetch(pageSize, pageToken)
		if err != nil {
			return "", err
		}
		it.items = append(it.items, items...)
		return nextPageToken, nil
	}

	it.pageInfo, it.nextFunc = iterator.NewPageInfo(fetch, it.bufLen, it.takeBuf)
	it.pageInfo.MaxSize = int(req.GetPageSize())
	it.pageInfo.Token = req.GetPageToken()

	return it
}

func (c *gkeInferenceQuickstartGRPCClient) GenerateOptimizedManifest(ctx context.Context, req *gkerecommenderpb.GenerateOptimizedManifestRequest, opts ...gax.CallOption) (*gkerecommenderpb.GenerateOptimizedManifestResponse, error) {
	ctx = gax.InsertMetadataIntoOutgoingContext(ctx, c.xGoogHeaders...)
	opts = append((*c.CallOptions).GenerateOptimizedManifest[0:len((*c.CallOptions).GenerateOptimizedManifest):len((*c.CallOptions).GenerateOptimizedManifest)], opts...)
	var resp *gkerecommenderpb.GenerateOptimizedManifestResponse
	err := gax.Invoke(ctx, func(ctx context.Context, settings gax.CallSettings) error {
		var err error
		resp, err = executeRPC(ctx, c.gkeInferenceQuickstartClient.GenerateOptimizedManifest, req, settings.GRPC, c.logger, "GenerateOptimizedManifest")
		return err
	}, opts...)
	if err != nil {
		return nil, err
	}
	return resp, nil
}

func (c *gkeInferenceQuickstartGRPCClient) FetchBenchmarkingData(ctx context.Context, req *gkerecommenderpb.FetchBenchmarkingDataRequest, opts ...gax.CallOption) (*gkerecommenderpb.FetchBenchmarkingDataResponse, error) {
	ctx = gax.InsertMetadataIntoOutgoingContext(ctx, c.xGoogHeaders...)
	opts = append((*c.CallOptions).FetchBenchmarkingData[0:len((*c.CallOptions).FetchBenchmarkingData):len((*c.CallOptions).FetchBenchmarkingData)], opts...)
	var resp *gkerecommenderpb.FetchBenchmarkingDataResponse
	err := gax.Invoke(ctx, func(ctx context.Context, settings gax.CallSettings) error {
		var err error
		resp, err = executeRPC(ctx, c.gkeInferenceQuickstartClient.FetchBenchmarkingData, req, settings.GRPC, c.logger, "FetchBenchmarkingData")
		return err
	}, opts...)
	if err != nil {
		return nil, err
	}
	return resp, nil
}

// FetchModels fetches available models. Open-source models follow the Huggingface Hub
// owner/model_name format.
func (c *gkeInferenceQuickstartRESTClient) FetchModels(ctx context.Context, req *gkerecommenderpb.FetchModelsRequest, opts ...gax.CallOption) *StringIterator {
	it := &StringIterator{}
	req = proto.Clone(req).(*gkerecommenderpb.FetchModelsRequest)
	unm := protojson.UnmarshalOptions{AllowPartial: true, DiscardUnknown: true}
	it.InternalFetch = func(pageSize int, pageToken string) ([]string, string, error) {
		resp := &gkerecommenderpb.FetchModelsResponse{}
		if pageToken != "" {
			req.PageToken = proto.String(pageToken)
		}
		if pageSize > math.MaxInt32 {
			req.PageSize = proto.Int32(int32(math.MaxInt32))
		} else if pageSize != 0 {
			req.PageSize = proto.Int32(int32(pageSize))
		}
		baseUrl, err := url.Parse(c.endpoint)
		if err != nil {
			return nil, "", err
		}
		baseUrl.Path += fmt.Sprintf("/v1/models:fetch")

		params := url.Values{}
		params.Add("$alt", "json;enum-encoding=int")
		if req != nil && req.PageSize != nil {
			params.Add("pageSize", fmt.Sprintf("%v", req.GetPageSize()))
		}
		if req != nil && req.PageToken != nil {
			params.Add("pageToken", fmt.Sprintf("%v", req.GetPageToken()))
		}

		baseUrl.RawQuery = params.Encode()

		// Build HTTP headers from client and context metadata.
		hds := append(c.xGoogHeaders, "Content-Type", "application/json")
		headers := gax.BuildHeaders(ctx, hds...)
		e := gax.Invoke(ctx, func(ctx context.Context, settings gax.CallSettings) error {
			if settings.Path != "" {
				baseUrl.Path = settings.Path
			}
			httpReq, err := http.NewRequest("GET", baseUrl.String(), nil)
			if err != nil {
				return err
			}
			httpReq.Header = headers

			buf, err := executeHTTPRequest(ctx, c.httpClient, httpReq, c.logger, nil, "FetchModels")
			if err != nil {
				return err
			}
			if err := unm.Unmarshal(buf, resp); err != nil {
				return err
			}

			return nil
		}, opts...)
		if e != nil {
			return nil, "", e
		}
		it.Response = resp
		return resp.GetModels(), resp.GetNextPageToken(), nil
	}

	fetch := func(pageSize int, pageToken string) (string, error) {
		items, nextPageToken, err := it.InternalFetch(pageSize, pageToken)
		if err != nil {
			return "", err
		}
		it.items = append(it.items, items...)
		return nextPageToken, nil
	}

	it.pageInfo, it.nextFunc = iterator.NewPageInfo(fetch, it.bufLen, it.takeBuf)
	it.pageInfo.MaxSize = int(req.GetPageSize())
	it.pageInfo.Token = req.GetPageToken()

	return it
}

// FetchModelServers fetches available model servers. Open-source model servers use simplified,
// lowercase names (e.g., vllm).
func (c *gkeInferenceQuickstartRESTClient) FetchModelServers(ctx context.Context, req *gkerecommenderpb.FetchModelServersRequest, opts ...gax.CallOption) *StringIterator {
	it := &StringIterator{}
	req = proto.Clone(req).(*gkerecommenderpb.FetchModelServersRequest)
	unm := protojson.UnmarshalOptions{AllowPartial: true, DiscardUnknown: true}
	it.InternalFetch = func(pageSize int, pageToken string) ([]string, string, error) {
		resp := &gkerecommenderpb.FetchModelServersResponse{}
		if pageToken != "" {
			req.PageToken = proto.String(pageToken)
		}
		if pageSize > math.MaxInt32 {
			req.PageSize = proto.Int32(int32(math.MaxInt32))
		} else if pageSize != 0 {
			req.PageSize = proto.Int32(int32(pageSize))
		}
		baseUrl, err := url.Parse(c.endpoint)
		if err != nil {
			return nil, "", err
		}
		baseUrl.Path += fmt.Sprintf("/v1/modelServers:fetch")

		params := url.Values{}
		params.Add("$alt", "json;enum-encoding=int")
		params.Add("model", fmt.Sprintf("%v", req.GetModel()))
		if req != nil && req.PageSize != nil {
			params.Add("pageSize", fmt.Sprintf("%v", req.GetPageSize()))
		}
		if req != nil && req.PageToken != nil {
			params.Add("pageToken", fmt.Sprintf("%v", req.GetPageToken()))
		}

		baseUrl.RawQuery = params.Encode()

		// Build HTTP headers from client and context metadata.
		hds := append(c.xGoogHeaders, "Content-Type", "application/json")
		headers := gax.BuildHeaders(ctx, hds...)
		e := gax.Invoke(ctx, func(ctx context.Context, settings gax.CallSettings) error {
			if settings.Path != "" {
				baseUrl.Path = settings.Path
			}
			httpReq, err := http.NewRequest("GET", baseUrl.String(), nil)
			if err != nil {
				return err
			}
			httpReq.Header = headers

			buf, err := executeHTTPRequest(ctx, c.httpClient, httpReq, c.logger, nil, "FetchModelServers")
			if err != nil {
				return err
			}
			if err := unm.Unmarshal(buf, resp); err != nil {
				return err
			}

			return nil
		}, opts...)
		if e != nil {
			return nil, "", e
		}
		it.Response = resp
		return resp.GetModelServers(), resp.GetNextPageToken(), nil
	}

	fetch := func(pageSize int, pageToken string) (string, error) {
		items, nextPageToken, err := it.InternalFetch(pageSize, pageToken)
		if err != nil {
			return "", err
		}
		it.items = append(it.items, items...)
		return nextPageToken, nil
	}

	it.pageInfo, it.nextFunc = iterator.NewPageInfo(fetch, it.bufLen, it.takeBuf)
	it.pageInfo.MaxSize = int(req.GetPageSize())
	it.pageInfo.Token = req.GetPageToken()

	return it
}

// FetchModelServerVersions fetches available model server versions. Open-source servers use their own
// versioning schemas (e.g., vllm uses semver like v1.0.0).
//
// Some model servers have different versioning schemas depending on the
// accelerator. For example, vllm uses semver on GPUs, but returns nightly
// build tags on TPUs. All available versions will be returned when different
// schemas are present.
func (c *gkeInferenceQuickstartRESTClient) FetchModelServerVersions(ctx context.Context, req *gkerecommenderpb.FetchModelServerVersionsRequest, opts ...gax.CallOption) *StringIterator {
	it := &StringIterator{}
	req = proto.Clone(req).(*gkerecommenderpb.FetchModelServerVersionsRequest)
	unm := protojson.UnmarshalOptions{AllowPartial: true, DiscardUnknown: true}
	it.InternalFetch = func(pageSize int, pageToken string) ([]string, string, error) {
		resp := &gkerecommenderpb.FetchModelServerVersionsResponse{}
		if pageToken != "" {
			req.PageToken = proto.String(pageToken)
		}
		if pageSize > math.MaxInt32 {
			req.PageSize = proto.Int32(int32(math.MaxInt32))
		} else if pageSize != 0 {
			req.PageSize = proto.Int32(int32(pageSize))
		}
		baseUrl, err := url.Parse(c.endpoint)
		if err != nil {
			return nil, "", err
		}
		baseUrl.Path += fmt.Sprintf("/v1/modelServerVersions:fetch")

		params := url.Values{}
		params.Add("$alt", "json;enum-encoding=int")
		params.Add("model", fmt.Sprintf("%v", req.GetModel()))
		params.Add("modelServer", fmt.Sprintf("%v", req.GetModelServer()))
		if req != nil && req.PageSize != nil {
			params.Add("pageSize", fmt.Sprintf("%v", req.GetPageSize()))
		}
		if req != nil && req.PageToken != nil {
			params.Add("pageToken", fmt.Sprintf("%v", req.GetPageToken()))
		}

		baseUrl.RawQuery = params.Encode()

		// Build HTTP headers from client and context metadata.
		hds := append(c.xGoogHeaders, "Content-Type", "application/json")
		headers := gax.BuildHeaders(ctx, hds...)
		e := gax.Invoke(ctx, func(ctx context.Context, settings gax.CallSettings) error {
			if settings.Path != "" {
				baseUrl.Path = settings.Path
			}
			httpReq, err := http.NewRequest("GET", baseUrl.String(), nil)
			if err != nil {
				return err
			}
			httpReq.Header = headers

			buf, err := executeHTTPRequest(ctx, c.httpClient, httpReq, c.logger, nil, "FetchModelServerVersions")
			if err != nil {
				return err
			}
			if err := unm.Unmarshal(buf, resp); err != nil {
				return err
			}

			return nil
		}, opts...)
		if e != nil {
			return nil, "", e
		}
		it.Response = resp
		return resp.GetModelServerVersions(), resp.GetNextPageToken(), nil
	}

	fetch := func(pageSize int, pageToken string) (string, error) {
		items, nextPageToken, err := it.InternalFetch(pageSize, pageToken)
		if err != nil {
			return "", err
		}
		it.items = append(it.items, items...)
		return nextPageToken, nil
	}

	it.pageInfo, it.nextFunc = iterator.NewPageInfo(fetch, it.bufLen, it.takeBuf)
	it.pageInfo.MaxSize = int(req.GetPageSize())
	it.pageInfo.Token = req.GetPageToken()

	return it
}

// FetchProfiles fetches available profiles. A profile contains performance metrics and
// cost information for a specific model server setup. Profiles can be
// filtered by parameters. If no filters are provided, all profiles are
// returned.
//
// Profiles display a single value per performance metric based on the
// provided performance requirements. If no requirements are given, the
// metrics represent the inflection point. See Run best practice inference
// with GKE Inference Quickstart
// recipes (at https://cloud.google.com/kubernetes-engine/docs/how-to/machine-learning/inference/inference-quickstart#how)
// for details.
func (c *gkeInferenceQuickstartRESTClient) FetchProfiles(ctx context.Context, req *gkerecommenderpb.FetchProfilesRequest, opts ...gax.CallOption) *ProfileIterator {
	it := &ProfileIterator{}
	req = proto.Clone(req).(*gkerecommenderpb.FetchProfilesRequest)
	m := protojson.MarshalOptions{AllowPartial: true, UseEnumNumbers: true}
	unm := protojson.UnmarshalOptions{AllowPartial: true, DiscardUnknown: true}
	it.InternalFetch = func(pageSize int, pageToken string) ([]*gkerecommenderpb.Profile, string, error) {
		resp := &gkerecommenderpb.FetchProfilesResponse{}
		if pageToken != "" {
			req.PageToken = proto.String(pageToken)
		}
		if pageSize > math.MaxInt32 {
			req.PageSize = proto.Int32(int32(math.MaxInt32))
		} else if pageSize != 0 {
			req.PageSize = proto.Int32(int32(pageSize))
		}
		jsonReq, err := m.Marshal(req)
		if err != nil {
			return nil, "", err
		}

		baseUrl, err := url.Parse(c.endpoint)
		if err != nil {
			return nil, "", err
		}
		baseUrl.Path += fmt.Sprintf("/v1/profiles:fetch")

		params := url.Values{}
		params.Add("$alt", "json;enum-encoding=int")

		baseUrl.RawQuery = params.Encode()

		// Build HTTP headers from client and context metadata.
		hds := append(c.xGoogHeaders, "Content-Type", "application/json")
		headers := gax.BuildHeaders(ctx, hds...)
		e := gax.Invoke(ctx, func(ctx context.Context, settings gax.CallSettings) error {
			if settings.Path != "" {
				baseUrl.Path = settings.Path
			}
			httpReq, err := http.NewRequest("POST", baseUrl.String(), bytes.NewReader(jsonReq))
			if err != nil {
				return err
			}
			httpReq.Header = headers

			buf, err := executeHTTPRequest(ctx, c.httpClient, httpReq, c.logger, jsonReq, "FetchProfiles")
			if err != nil {
				return err
			}
			if err := unm.Unmarshal(buf, resp); err != nil {
				return err
			}

			return nil
		}, opts...)
		if e != nil {
			return nil, "", e
		}
		it.Response = resp
		return resp.GetProfile(), resp.GetNextPageToken(), nil
	}

	fetch := func(pageSize int, pageToken string) (string, error) {
		items, nextPageToken, err := it.InternalFetch(pageSize, pageToken)
		if err != nil {
			return "", err
		}
		it.items = append(it.items, items...)
		return nextPageToken, nil
	}

	it.pageInfo, it.nextFunc = iterator.NewPageInfo(fetch, it.bufLen, it.takeBuf)
	it.pageInfo.MaxSize = int(req.GetPageSize())
	it.pageInfo.Token = req.GetPageToken()

	return it
}

// GenerateOptimizedManifest generates an optimized deployment manifest for a given model and model
// server, based on the specified accelerator, performance targets, and
// configurations. See Run best practice inference with GKE Inference
// Quickstart
// recipes (at https://cloud.google.com/kubernetes-engine/docs/how-to/machine-learning/inference/inference-quickstart)
// for deployment details.
func (c *gkeInferenceQuickstartRESTClient) GenerateOptimizedManifest(ctx context.Context, req *gkerecommenderpb.GenerateOptimizedManifestRequest, opts ...gax.CallOption) (*gkerecommenderpb.GenerateOptimizedManifestResponse, error) {
	m := protojson.MarshalOptions{AllowPartial: true, UseEnumNumbers: true}
	jsonReq, err := m.Marshal(req)
	if err != nil {
		return nil, err
	}

	baseUrl, err := url.Parse(c.endpoint)
	if err != nil {
		return nil, err
	}
	baseUrl.Path += fmt.Sprintf("/v1/optimizedManifest:generate")

	params := url.Values{}
	params.Add("$alt", "json;enum-encoding=int")

	baseUrl.RawQuery = params.Encode()

	// Build HTTP headers from client and context metadata.
	hds := append(c.xGoogHeaders, "Content-Type", "application/json")
	headers := gax.BuildHeaders(ctx, hds...)
	opts = append((*c.CallOptions).GenerateOptimizedManifest[0:len((*c.CallOptions).GenerateOptimizedManifest):len((*c.CallOptions).GenerateOptimizedManifest)], opts...)
	unm := protojson.UnmarshalOptions{AllowPartial: true, DiscardUnknown: true}
	resp := &gkerecommenderpb.GenerateOptimizedManifestResponse{}
	e := gax.Invoke(ctx, func(ctx context.Context, settings gax.CallSettings) error {
		if settings.Path != "" {
			baseUrl.Path = settings.Path
		}
		httpReq, err := http.NewRequest("POST", baseUrl.String(), bytes.NewReader(jsonReq))
		if err != nil {
			return err
		}
		httpReq = httpReq.WithContext(ctx)
		httpReq.Header = headers

		buf, err := executeHTTPRequest(ctx, c.httpClient, httpReq, c.logger, jsonReq, "GenerateOptimizedManifest")
		if err != nil {
			return err
		}

		if err := unm.Unmarshal(buf, resp); err != nil {
			return err
		}

		return nil
	}, opts...)
	if e != nil {
		return nil, e
	}
	return resp, nil
}

// FetchBenchmarkingData fetches all of the benchmarking data available for a profile. Benchmarking
// data returns all of the performance metrics available for a given model
// server setup on a given instance type.
func (c *gkeInferenceQuickstartRESTClient) FetchBenchmarkingData(ctx context.Context, req *gkerecommenderpb.FetchBenchmarkingDataRequest, opts ...gax.CallOption) (*gkerecommenderpb.FetchBenchmarkingDataResponse, error) {
	m := protojson.MarshalOptions{AllowPartial: true, UseEnumNumbers: true}
	jsonReq, err := m.Marshal(req)
	if err != nil {
		return nil, err
	}

	baseUrl, err := url.Parse(c.endpoint)
	if err != nil {
		return nil, err
	}
	baseUrl.Path += fmt.Sprintf("/v1/benchmarkingData:fetch")

	params := url.Values{}
	params.Add("$alt", "json;enum-encoding=int")

	baseUrl.RawQuery = params.Encode()

	// Build HTTP headers from client and context metadata.
	hds := append(c.xGoogHeaders, "Content-Type", "application/json")
	headers := gax.BuildHeaders(ctx, hds...)
	opts = append((*c.CallOptions).FetchBenchmarkingData[0:len((*c.CallOptions).FetchBenchmarkingData):len((*c.CallOptions).FetchBenchmarkingData)], opts...)
	unm := protojson.UnmarshalOptions{AllowPartial: true, DiscardUnknown: true}
	resp := &gkerecommenderpb.FetchBenchmarkingDataResponse{}
	e := gax.Invoke(ctx, func(ctx context.Context, settings gax.CallSettings) error {
		if settings.Path != "" {
			baseUrl.Path = settings.Path
		}
		httpReq, err := http.NewRequest("POST", baseUrl.String(), bytes.NewReader(jsonReq))
		if err != nil {
			return err
		}
		httpReq = httpReq.WithContext(ctx)
		httpReq.Header = headers

		buf, err := executeHTTPRequest(ctx, c.httpClient, httpReq, c.logger, jsonReq, "FetchBenchmarkingData")
		if err != nil {
			return err
		}

		if err := unm.Unmarshal(buf, resp); err != nil {
			return err
		}

		return nil
	}, opts...)
	if e != nil {
		return nil, e
	}
	return resp, nil
}
