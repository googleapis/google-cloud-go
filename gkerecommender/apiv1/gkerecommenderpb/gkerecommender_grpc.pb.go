// Copyright 2025 Google LLC
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//     http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

// Code generated by protoc-gen-go-grpc. DO NOT EDIT.
// versions:
// - protoc-gen-go-grpc v1.3.0
// - protoc             v4.25.7
// source: google/cloud/gkerecommender/v1/gkerecommender.proto

package gkerecommenderpb

import (
	context "context"

	grpc "google.golang.org/grpc"
	codes "google.golang.org/grpc/codes"
	status "google.golang.org/grpc/status"
)

// This is a compile-time assertion to ensure that this generated file
// is compatible with the grpc package it is being compiled against.
// Requires gRPC-Go v1.32.0 or later.
const _ = grpc.SupportPackageIsVersion7

const (
	GkeInferenceQuickstart_FetchModels_FullMethodName               = "/google.cloud.gkerecommender.v1.GkeInferenceQuickstart/FetchModels"
	GkeInferenceQuickstart_FetchModelServers_FullMethodName         = "/google.cloud.gkerecommender.v1.GkeInferenceQuickstart/FetchModelServers"
	GkeInferenceQuickstart_FetchModelServerVersions_FullMethodName  = "/google.cloud.gkerecommender.v1.GkeInferenceQuickstart/FetchModelServerVersions"
	GkeInferenceQuickstart_FetchProfiles_FullMethodName             = "/google.cloud.gkerecommender.v1.GkeInferenceQuickstart/FetchProfiles"
	GkeInferenceQuickstart_GenerateOptimizedManifest_FullMethodName = "/google.cloud.gkerecommender.v1.GkeInferenceQuickstart/GenerateOptimizedManifest"
	GkeInferenceQuickstart_FetchBenchmarkingData_FullMethodName     = "/google.cloud.gkerecommender.v1.GkeInferenceQuickstart/FetchBenchmarkingData"
)

// GkeInferenceQuickstartClient is the client API for GkeInferenceQuickstart service.
//
// For semantics around ctx use and closing/ending streaming RPCs, please refer to https://pkg.go.dev/google.golang.org/grpc/?tab=doc#ClientConn.NewStream.
type GkeInferenceQuickstartClient interface {
	// Fetches available models. Open-source models follow the Huggingface Hub
	// `owner/model_name` format.
	FetchModels(ctx context.Context, in *FetchModelsRequest, opts ...grpc.CallOption) (*FetchModelsResponse, error)
	// Fetches available model servers. Open-source model servers use simplified,
	// lowercase names (e.g., `vllm`).
	FetchModelServers(ctx context.Context, in *FetchModelServersRequest, opts ...grpc.CallOption) (*FetchModelServersResponse, error)
	// Fetches available model server versions. Open-source servers use their own
	// versioning schemas (e.g., `vllm` uses semver like `v1.0.0`).
	//
	// Some model servers have different versioning schemas depending on the
	// accelerator. For example, `vllm` uses semver on GPUs, but returns nightly
	// build tags on TPUs. All available versions will be returned when different
	// schemas are present.
	FetchModelServerVersions(ctx context.Context, in *FetchModelServerVersionsRequest, opts ...grpc.CallOption) (*FetchModelServerVersionsResponse, error)
	// Fetches available profiles. A profile contains performance metrics and
	// cost information for a specific model server setup. Profiles can be
	// filtered by parameters. If no filters are provided, all profiles are
	// returned.
	//
	// Profiles display a single value per performance metric based on the
	// provided performance requirements. If no requirements are given, the
	// metrics represent the inflection point. See [Run best practice inference
	// with GKE Inference Quickstart
	// recipes](https://cloud.google.com/kubernetes-engine/docs/how-to/machine-learning/inference/inference-quickstart#how)
	// for details.
	FetchProfiles(ctx context.Context, in *FetchProfilesRequest, opts ...grpc.CallOption) (*FetchProfilesResponse, error)
	// Generates an optimized deployment manifest for a given model and model
	// server, based on the specified accelerator, performance targets, and
	// configurations. See [Run best practice inference with GKE Inference
	// Quickstart
	// recipes](https://cloud.google.com/kubernetes-engine/docs/how-to/machine-learning/inference/inference-quickstart)
	// for deployment details.
	GenerateOptimizedManifest(ctx context.Context, in *GenerateOptimizedManifestRequest, opts ...grpc.CallOption) (*GenerateOptimizedManifestResponse, error)
	// Fetches all of the benchmarking data available for a profile. Benchmarking
	// data returns all of the performance metrics available for a given model
	// server setup on a given instance type.
	FetchBenchmarkingData(ctx context.Context, in *FetchBenchmarkingDataRequest, opts ...grpc.CallOption) (*FetchBenchmarkingDataResponse, error)
}

type gkeInferenceQuickstartClient struct {
	cc grpc.ClientConnInterface
}

func NewGkeInferenceQuickstartClient(cc grpc.ClientConnInterface) GkeInferenceQuickstartClient {
	return &gkeInferenceQuickstartClient{cc}
}

func (c *gkeInferenceQuickstartClient) FetchModels(ctx context.Context, in *FetchModelsRequest, opts ...grpc.CallOption) (*FetchModelsResponse, error) {
	out := new(FetchModelsResponse)
	err := c.cc.Invoke(ctx, GkeInferenceQuickstart_FetchModels_FullMethodName, in, out, opts...)
	if err != nil {
		return nil, err
	}
	return out, nil
}

func (c *gkeInferenceQuickstartClient) FetchModelServers(ctx context.Context, in *FetchModelServersRequest, opts ...grpc.CallOption) (*FetchModelServersResponse, error) {
	out := new(FetchModelServersResponse)
	err := c.cc.Invoke(ctx, GkeInferenceQuickstart_FetchModelServers_FullMethodName, in, out, opts...)
	if err != nil {
		return nil, err
	}
	return out, nil
}

func (c *gkeInferenceQuickstartClient) FetchModelServerVersions(ctx context.Context, in *FetchModelServerVersionsRequest, opts ...grpc.CallOption) (*FetchModelServerVersionsResponse, error) {
	out := new(FetchModelServerVersionsResponse)
	err := c.cc.Invoke(ctx, GkeInferenceQuickstart_FetchModelServerVersions_FullMethodName, in, out, opts...)
	if err != nil {
		return nil, err
	}
	return out, nil
}

func (c *gkeInferenceQuickstartClient) FetchProfiles(ctx context.Context, in *FetchProfilesRequest, opts ...grpc.CallOption) (*FetchProfilesResponse, error) {
	out := new(FetchProfilesResponse)
	err := c.cc.Invoke(ctx, GkeInferenceQuickstart_FetchProfiles_FullMethodName, in, out, opts...)
	if err != nil {
		return nil, err
	}
	return out, nil
}

func (c *gkeInferenceQuickstartClient) GenerateOptimizedManifest(ctx context.Context, in *GenerateOptimizedManifestRequest, opts ...grpc.CallOption) (*GenerateOptimizedManifestResponse, error) {
	out := new(GenerateOptimizedManifestResponse)
	err := c.cc.Invoke(ctx, GkeInferenceQuickstart_GenerateOptimizedManifest_FullMethodName, in, out, opts...)
	if err != nil {
		return nil, err
	}
	return out, nil
}

func (c *gkeInferenceQuickstartClient) FetchBenchmarkingData(ctx context.Context, in *FetchBenchmarkingDataRequest, opts ...grpc.CallOption) (*FetchBenchmarkingDataResponse, error) {
	out := new(FetchBenchmarkingDataResponse)
	err := c.cc.Invoke(ctx, GkeInferenceQuickstart_FetchBenchmarkingData_FullMethodName, in, out, opts...)
	if err != nil {
		return nil, err
	}
	return out, nil
}

// GkeInferenceQuickstartServer is the server API for GkeInferenceQuickstart service.
// All implementations should embed UnimplementedGkeInferenceQuickstartServer
// for forward compatibility
type GkeInferenceQuickstartServer interface {
	// Fetches available models. Open-source models follow the Huggingface Hub
	// `owner/model_name` format.
	FetchModels(context.Context, *FetchModelsRequest) (*FetchModelsResponse, error)
	// Fetches available model servers. Open-source model servers use simplified,
	// lowercase names (e.g., `vllm`).
	FetchModelServers(context.Context, *FetchModelServersRequest) (*FetchModelServersResponse, error)
	// Fetches available model server versions. Open-source servers use their own
	// versioning schemas (e.g., `vllm` uses semver like `v1.0.0`).
	//
	// Some model servers have different versioning schemas depending on the
	// accelerator. For example, `vllm` uses semver on GPUs, but returns nightly
	// build tags on TPUs. All available versions will be returned when different
	// schemas are present.
	FetchModelServerVersions(context.Context, *FetchModelServerVersionsRequest) (*FetchModelServerVersionsResponse, error)
	// Fetches available profiles. A profile contains performance metrics and
	// cost information for a specific model server setup. Profiles can be
	// filtered by parameters. If no filters are provided, all profiles are
	// returned.
	//
	// Profiles display a single value per performance metric based on the
	// provided performance requirements. If no requirements are given, the
	// metrics represent the inflection point. See [Run best practice inference
	// with GKE Inference Quickstart
	// recipes](https://cloud.google.com/kubernetes-engine/docs/how-to/machine-learning/inference/inference-quickstart#how)
	// for details.
	FetchProfiles(context.Context, *FetchProfilesRequest) (*FetchProfilesResponse, error)
	// Generates an optimized deployment manifest for a given model and model
	// server, based on the specified accelerator, performance targets, and
	// configurations. See [Run best practice inference with GKE Inference
	// Quickstart
	// recipes](https://cloud.google.com/kubernetes-engine/docs/how-to/machine-learning/inference/inference-quickstart)
	// for deployment details.
	GenerateOptimizedManifest(context.Context, *GenerateOptimizedManifestRequest) (*GenerateOptimizedManifestResponse, error)
	// Fetches all of the benchmarking data available for a profile. Benchmarking
	// data returns all of the performance metrics available for a given model
	// server setup on a given instance type.
	FetchBenchmarkingData(context.Context, *FetchBenchmarkingDataRequest) (*FetchBenchmarkingDataResponse, error)
}

// UnimplementedGkeInferenceQuickstartServer should be embedded to have forward compatible implementations.
type UnimplementedGkeInferenceQuickstartServer struct {
}

func (UnimplementedGkeInferenceQuickstartServer) FetchModels(context.Context, *FetchModelsRequest) (*FetchModelsResponse, error) {
	return nil, status.Errorf(codes.Unimplemented, "method FetchModels not implemented")
}
func (UnimplementedGkeInferenceQuickstartServer) FetchModelServers(context.Context, *FetchModelServersRequest) (*FetchModelServersResponse, error) {
	return nil, status.Errorf(codes.Unimplemented, "method FetchModelServers not implemented")
}
func (UnimplementedGkeInferenceQuickstartServer) FetchModelServerVersions(context.Context, *FetchModelServerVersionsRequest) (*FetchModelServerVersionsResponse, error) {
	return nil, status.Errorf(codes.Unimplemented, "method FetchModelServerVersions not implemented")
}
func (UnimplementedGkeInferenceQuickstartServer) FetchProfiles(context.Context, *FetchProfilesRequest) (*FetchProfilesResponse, error) {
	return nil, status.Errorf(codes.Unimplemented, "method FetchProfiles not implemented")
}
func (UnimplementedGkeInferenceQuickstartServer) GenerateOptimizedManifest(context.Context, *GenerateOptimizedManifestRequest) (*GenerateOptimizedManifestResponse, error) {
	return nil, status.Errorf(codes.Unimplemented, "method GenerateOptimizedManifest not implemented")
}
func (UnimplementedGkeInferenceQuickstartServer) FetchBenchmarkingData(context.Context, *FetchBenchmarkingDataRequest) (*FetchBenchmarkingDataResponse, error) {
	return nil, status.Errorf(codes.Unimplemented, "method FetchBenchmarkingData not implemented")
}

// UnsafeGkeInferenceQuickstartServer may be embedded to opt out of forward compatibility for this service.
// Use of this interface is not recommended, as added methods to GkeInferenceQuickstartServer will
// result in compilation errors.
type UnsafeGkeInferenceQuickstartServer interface {
	mustEmbedUnimplementedGkeInferenceQuickstartServer()
}

func RegisterGkeInferenceQuickstartServer(s grpc.ServiceRegistrar, srv GkeInferenceQuickstartServer) {
	s.RegisterService(&GkeInferenceQuickstart_ServiceDesc, srv)
}

func _GkeInferenceQuickstart_FetchModels_Handler(srv interface{}, ctx context.Context, dec func(interface{}) error, interceptor grpc.UnaryServerInterceptor) (interface{}, error) {
	in := new(FetchModelsRequest)
	if err := dec(in); err != nil {
		return nil, err
	}
	if interceptor == nil {
		return srv.(GkeInferenceQuickstartServer).FetchModels(ctx, in)
	}
	info := &grpc.UnaryServerInfo{
		Server:     srv,
		FullMethod: GkeInferenceQuickstart_FetchModels_FullMethodName,
	}
	handler := func(ctx context.Context, req interface{}) (interface{}, error) {
		return srv.(GkeInferenceQuickstartServer).FetchModels(ctx, req.(*FetchModelsRequest))
	}
	return interceptor(ctx, in, info, handler)
}

func _GkeInferenceQuickstart_FetchModelServers_Handler(srv interface{}, ctx context.Context, dec func(interface{}) error, interceptor grpc.UnaryServerInterceptor) (interface{}, error) {
	in := new(FetchModelServersRequest)
	if err := dec(in); err != nil {
		return nil, err
	}
	if interceptor == nil {
		return srv.(GkeInferenceQuickstartServer).FetchModelServers(ctx, in)
	}
	info := &grpc.UnaryServerInfo{
		Server:     srv,
		FullMethod: GkeInferenceQuickstart_FetchModelServers_FullMethodName,
	}
	handler := func(ctx context.Context, req interface{}) (interface{}, error) {
		return srv.(GkeInferenceQuickstartServer).FetchModelServers(ctx, req.(*FetchModelServersRequest))
	}
	return interceptor(ctx, in, info, handler)
}

func _GkeInferenceQuickstart_FetchModelServerVersions_Handler(srv interface{}, ctx context.Context, dec func(interface{}) error, interceptor grpc.UnaryServerInterceptor) (interface{}, error) {
	in := new(FetchModelServerVersionsRequest)
	if err := dec(in); err != nil {
		return nil, err
	}
	if interceptor == nil {
		return srv.(GkeInferenceQuickstartServer).FetchModelServerVersions(ctx, in)
	}
	info := &grpc.UnaryServerInfo{
		Server:     srv,
		FullMethod: GkeInferenceQuickstart_FetchModelServerVersions_FullMethodName,
	}
	handler := func(ctx context.Context, req interface{}) (interface{}, error) {
		return srv.(GkeInferenceQuickstartServer).FetchModelServerVersions(ctx, req.(*FetchModelServerVersionsRequest))
	}
	return interceptor(ctx, in, info, handler)
}

func _GkeInferenceQuickstart_FetchProfiles_Handler(srv interface{}, ctx context.Context, dec func(interface{}) error, interceptor grpc.UnaryServerInterceptor) (interface{}, error) {
	in := new(FetchProfilesRequest)
	if err := dec(in); err != nil {
		return nil, err
	}
	if interceptor == nil {
		return srv.(GkeInferenceQuickstartServer).FetchProfiles(ctx, in)
	}
	info := &grpc.UnaryServerInfo{
		Server:     srv,
		FullMethod: GkeInferenceQuickstart_FetchProfiles_FullMethodName,
	}
	handler := func(ctx context.Context, req interface{}) (interface{}, error) {
		return srv.(GkeInferenceQuickstartServer).FetchProfiles(ctx, req.(*FetchProfilesRequest))
	}
	return interceptor(ctx, in, info, handler)
}

func _GkeInferenceQuickstart_GenerateOptimizedManifest_Handler(srv interface{}, ctx context.Context, dec func(interface{}) error, interceptor grpc.UnaryServerInterceptor) (interface{}, error) {
	in := new(GenerateOptimizedManifestRequest)
	if err := dec(in); err != nil {
		return nil, err
	}
	if interceptor == nil {
		return srv.(GkeInferenceQuickstartServer).GenerateOptimizedManifest(ctx, in)
	}
	info := &grpc.UnaryServerInfo{
		Server:     srv,
		FullMethod: GkeInferenceQuickstart_GenerateOptimizedManifest_FullMethodName,
	}
	handler := func(ctx context.Context, req interface{}) (interface{}, error) {
		return srv.(GkeInferenceQuickstartServer).GenerateOptimizedManifest(ctx, req.(*GenerateOptimizedManifestRequest))
	}
	return interceptor(ctx, in, info, handler)
}

func _GkeInferenceQuickstart_FetchBenchmarkingData_Handler(srv interface{}, ctx context.Context, dec func(interface{}) error, interceptor grpc.UnaryServerInterceptor) (interface{}, error) {
	in := new(FetchBenchmarkingDataRequest)
	if err := dec(in); err != nil {
		return nil, err
	}
	if interceptor == nil {
		return srv.(GkeInferenceQuickstartServer).FetchBenchmarkingData(ctx, in)
	}
	info := &grpc.UnaryServerInfo{
		Server:     srv,
		FullMethod: GkeInferenceQuickstart_FetchBenchmarkingData_FullMethodName,
	}
	handler := func(ctx context.Context, req interface{}) (interface{}, error) {
		return srv.(GkeInferenceQuickstartServer).FetchBenchmarkingData(ctx, req.(*FetchBenchmarkingDataRequest))
	}
	return interceptor(ctx, in, info, handler)
}

// GkeInferenceQuickstart_ServiceDesc is the grpc.ServiceDesc for GkeInferenceQuickstart service.
// It's only intended for direct use with grpc.RegisterService,
// and not to be introspected or modified (even as a copy)
var GkeInferenceQuickstart_ServiceDesc = grpc.ServiceDesc{
	ServiceName: "google.cloud.gkerecommender.v1.GkeInferenceQuickstart",
	HandlerType: (*GkeInferenceQuickstartServer)(nil),
	Methods: []grpc.MethodDesc{
		{
			MethodName: "FetchModels",
			Handler:    _GkeInferenceQuickstart_FetchModels_Handler,
		},
		{
			MethodName: "FetchModelServers",
			Handler:    _GkeInferenceQuickstart_FetchModelServers_Handler,
		},
		{
			MethodName: "FetchModelServerVersions",
			Handler:    _GkeInferenceQuickstart_FetchModelServerVersions_Handler,
		},
		{
			MethodName: "FetchProfiles",
			Handler:    _GkeInferenceQuickstart_FetchProfiles_Handler,
		},
		{
			MethodName: "GenerateOptimizedManifest",
			Handler:    _GkeInferenceQuickstart_GenerateOptimizedManifest_Handler,
		},
		{
			MethodName: "FetchBenchmarkingData",
			Handler:    _GkeInferenceQuickstart_FetchBenchmarkingData_Handler,
		},
	},
	Streams:  []grpc.StreamDesc{},
	Metadata: "google/cloud/gkerecommender/v1/gkerecommender.proto",
}
